Script started on 2025-10-18 23:31:07+00:00 [TERM="xterm-256color" TTY="/dev/pts/10" COLUMNS="120" LINES="39"]
[1;35m    ______              __                _
   / ____/___   ____ _ / /_ __  __ _____ (_)____  ___
  / /_   / _ \ / __ `// __// / / // ___// //_  / / _ \
 / __/  /  __// /_/ // /_ / /_/ // /   / /  / /_/  __/
/_/     \___/ \__,_/ \__/ \__,_//_/   /_/  /___/\___/
======================================================[0m

ã€ç›®å½•åŠä½œç”¨ã€‘

+------------------+---------------------------------+---------+---------------------------------------------------------+
|  ç›®å½•åç§°        | è·¯å¾„                            | IO æ€§èƒ½ |  è¯´æ˜                                                   |
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  äº‘ç«¯åŒæ­¥ç›®å½•    |  /home/featurize/work           | æ…¢      |  äº‘åŒæ­¥ç›˜ä¸­çš„æ•°æ®ä¼šä¸€ç›´è·Ÿéšç”¨æˆ·ï¼Œä¸ä¼šéšå®ä¾‹é€€è¿˜è¢«é”€æ¯ï¼Œ |
|                  |                                 |         |  ä½†å…¶è¯»å–/å†™å…¥æ€§èƒ½éå¸¸å·®ã€‚                              |
|                  |                                 |         |  æ‰€ä»¥ä¸€å®šä¸è¦åœ¨è¿™é‡Œä¿å­˜æ•°æ®é›†ï¼Œå¦åˆ™ä¼šä¸¥é‡å½±å“è®­ç»ƒæ€§èƒ½   |
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  æ•°æ®é›†ä¸‹è½½ç›®å½•  |  /home/featurize/data           | å¿«      |  æ·»åŠ æ•°æ®é›†ä¼šä¸‹è½½å¹¶è§£å‹è‡³æ­¤ç›®å½•ï¼Œè¯¥ç›®å½•ç£ç›˜ä¸ºæœ¬åœ°é«˜é€Ÿ   |
|                  |                                 |         |  ç£ç›˜ï¼Œå› æ­¤è¯»å†™å¾ˆå¿«ã€‚å®ä¾‹é”€æ¯åè‡ªåŠ¨åˆ é™¤                 | 
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  å…¶ä»–ç›®å½•        |  N / A                          | å¿«      |  å…¶ä»–ç›®å½•å‡ä¸ºæœ¬åœ°é«˜é€Ÿç£ç›˜ï¼Œå®ä¾‹é”€æ¯åè‡ªåŠ¨åˆ é™¤           |
+------------------+---------------------------------+---------+---------------------------------------------------------+

ã€æœ€ä½³å®è·µã€‘

[0;32m âœ…  å§‹ç»ˆä½¿ç”¨æ•°æ®é›†åŠŸèƒ½æ¥æ·»åŠ æ•°æ®ï¼Œæ·»åŠ å®Œæˆåç›´æ¥ä½¿ç”¨ï¼Œä¸è¦å†ç§»åŠ¨æ•°æ®çš„ä½ç½®ã€‚
[0;32m âœ…  å§‹ç»ˆå°†ä»£ç ä¿å­˜è‡³ã€Œäº‘ç«¯åŒæ­¥ç›®å½•ã€ä¸­ã€‚
[0;32m âœ…  é‡è¦çš„æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨ã€Œäº‘ç«¯åŒæ­¥ç›®å½•ã€ï¼Œä¸é‡è¦çš„æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨å…¶ä»–ä½ç½®ã€‚
[0;32m âœ…  å§‹ç»ˆä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼Œè€Œä¸æ˜¯ç”¨ condaï¼Œå¦‚æ— å¿…è¦ï¼Œä¸è¦åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œé™¤éä½ çŸ¥é“è‡ªå·±åœ¨åšä»€ä¹ˆã€‚
[0;32m âœ…  å¸¸ç”¨çš„åŒ…å¯ä½¿ç”¨ pip install --user xxx å®‰è£…ï¼Œè¿™æ ·ä¸‹æ¬¡ä½¿ç”¨æ— éœ€é‡å¤å®‰è£…ã€‚ [0m

ã€æ³¨æ„äº‹é¡¹ã€‘

[0;31m â›”ï¸  äº‘ç«¯åŒæ­¥ç›®å½•ï¼ˆworkç›®å½•ï¼‰æœ‰é…é¢é™åˆ¶ï¼Œè¶…è¿‡é…é¢å°†äº§ç”Ÿè´¹ç”¨ã€‚å…·ä½“çš„é¢åº¦å¯ç‚¹å‡»å³ä¸Šè§’çš„å¤´åƒç¡®è®¤ï¼Œç”¨é‡è¯·ä½¿ç”¨ `du -sh ~/work/` æŸ¥çœ‹ã€‚
[0;31m â›”ï¸  è¯·ä¸è¦åˆ é™¤ conda çš„ base ç¯å¢ƒï¼Œè¿™ä¼šå¯¼è‡´æ— æ³•è®¿é—®å·¥ä½œåŒºã€‚
[0;31m â›”ï¸  Featurize ç¦æ­¢æŒ–çŸ¿ï¼Œè¯·ä¸è¦ä½¿ç”¨ featurize çš„å®ä¾‹æŒ–çŸ¿ï¼Œä¸€ç»å‘ç°ç›´æ¥å°å·æ•ä¸é€€æ¬¾ã€‚



[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[7mpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[27m[54D[27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m|[27m [27mt[27me[27me[27m [27m-[27ma[27m [27mo[27mc[27mr[27m_[27ml[27mo[27mg[27m_[27m$[27m([27md[27ma[27mt[27me[27m [27m+[27m%[27mY[27m%[27mm[27m%[27md[27m)[27m.[27ml[27mo[27mg[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-18 23:32:05] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-18 23:32:11] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-18 23:32:11] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-18 23:32:11] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_233205.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-18 23:32:11] å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
ğŸ”„ å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
[2025-10-18 23:32:11] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-18 23:32:11] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-18 23:32:11] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-18 23:32:11] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-18 23:32:28] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 16.47 ç§’
[2025-10-18 23:32:28] è¯†åˆ«å†…å®¹: F
1
å£
â–¡
F
æ–‡å­¦è¿åŠ¨
*
:
äºŒ
å¤æ–‡è¿åŠ¨
å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€ç§æ–‡ä½“å’Œæ–‡å­¦è¯­è¨€çš„é©...
[2025-10-18 23:32:28] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 16.61 ç§’
[2025-10-18 23:32:28] è¯†åˆ«å†…å®¹: ä¸åŒç¨‹åº¦ä¸Šåæ˜ äº†ç¤¾ä¼šçš„æœ¬è´¨ã€‚
æ–°ä¹åºœè¿åŠ¨ä½œä¸ºæ–‡å­¦å²ä¸Šçš„ä¸€ç§æ–‡å­¦æ€æ½®ï¼Œå¯¹åä¸–æ–‡å­¦
äº§ç”Ÿäº†å¹¿æ³›çš„å½±å“ï¼Œåœ¨...
[2025-10-18 23:32:29] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 17.50 ç§’
[2025-10-18 23:32:29] è¯†åˆ«å†…å®¹: è¿™äº›å¾é›†çš„æ°‘æ­Œä¹Ÿç§°ä½œ
ä¹åºœâ€
4
æ–°ä¹åºœæ˜¯ç”¨æ–°é¢˜æåˆ›ä½œçš„
0
ä¹æ›²å’Œè¯—ï¼Œå’Œä¹åºœå¤é¢˜ç›¸å¯¹è€Œç§°ã€‚
'
å”...
[2025-10-18 23:32:30] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 19.15 ç§’
[2025-10-18 23:32:30] è¯†åˆ«å†…å®¹: *
å¼ æ–‡ç« åº”æ˜¯ä½œè€…çœŸå®æƒ…æ„Ÿçš„æµéœ²ï¼Œ
åå¯¹æ— ç—…å‘»åŸï¼Œ
çŸ«æ‰é€ 
ä½œçš„ä¸è‰¯æ–‡é£ï¼Œ
æŒ‡å‡ºï¼š
å¤§å‡¡ç‰©ä¸å¾—å…¶å¹³åˆ™...

âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: '0032.png'
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[?1l>[?2004l
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-18 23:36:35] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-18 23:36:42] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-18 23:36:42] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-18 23:36:42] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_233635.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-18 23:36:42] å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
ğŸ”„ å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
[2025-10-18 23:36:42] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-18 23:36:42] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-18 23:36:42] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-18 23:36:42] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-18 23:36:59] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 16.66 ç§’
[2025-10-18 23:36:59] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 16.67 ç§’
[2025-10-18 23:36:59] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:36:59] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:36:59] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 16.85 ç§’
[2025-10-18 23:36:59] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:36:59] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 17.22 ç§’
[2025-10-18 23:36:59] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:36:59] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-18 23:36:59] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_233635.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-18 23:42:40] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-18 23:42:46] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-18 23:42:46] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-18 23:42:46] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234240.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-18 23:42:46] å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
ğŸ”„ å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
[2025-10-18 23:42:46] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-18 23:42:46] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-18 23:42:46] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-18 23:42:46] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-18 23:43:01] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 15.41 ç§’
[2025-10-18 23:43:01] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:43:03] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 17.36 ç§’
[2025-10-18 23:43:03] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:43:04] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 18.01 ç§’
[2025-10-18 23:43:04] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:43:04] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 18.42 ç§’
[2025-10-18 23:43:04] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:43:04] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-18 23:43:04] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234240.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[7m{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_r[7me[7mview.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> o[7mc[7mr_review.log 2>&1[27m[K
[K[3A[14C[27m{[27m [27me[27mc[27mh[27mo[27m [27m"[27m=[27m=[27m=[27m [27må¤[27m[27mç›˜[27m[27mè®°[27m[27må½•[27m[27m:[27m [27m$[27m([27md[27ma[27mt[27me[27m [27m'[27m+[27m%[27mY[27m-[27m%[27mm[27m-[27m%[27md[27m [27m%[27mH[27m:[27m%[27mM[27m:[27m%[27mS[27m'[27m)[27m [27m=[27m=[27m=[27m"[27m;[27m [27me[27mc[27mh[27mo[27m [27m"[27mæ‰§[27m[27mè¡Œ[27m[27må‘½[27m[27mä»¤[27m[27m:[27m [27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m$[27m@[27m"[27m;[27m [27m}[27m [27m>[27m>[27m [27mo[27mc[27mr[27m_[27mre[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m2[27m>[27m&[27m1[27m [27m&[27m&[27m [27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m"[27m$[27m@[27m"[27m [27m|[27m [27mt[27me[27me[27m [27m-[27ma[27m [27mo[27mc[27mr[27m_[27mr[27me[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m&[27m&[27m [27me[27mc[27mh[27mo[27m [27m"[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m"[27m [27m>[27m>[27m [27moc[27mr[27m_[27mr[27me[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m2[27m>[27m&[27m1[1B[K[?1l>[?2004l
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-18 23:46:37] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-18 23:46:44] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-18 23:46:44] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-18 23:46:44] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234637.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-18 23:46:44] å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
ğŸ”„ å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
[2025-10-18 23:46:44] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-18 23:46:44] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-18 23:46:44] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-18 23:46:44] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-18 23:47:03] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 19.38 ç§’
[2025-10-18 23:47:03] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:47:04] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 19.72 ç§’
[2025-10-18 23:47:04] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:47:04] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 20.26 ç§’
[2025-10-18 23:47:04] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:47:04] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 20.54 ç§’
[2025-10-18 23:47:04] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:47:04] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-18 23:47:04] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234637.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-18 23:49:51] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-18 23:49:57] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-18 23:49:57] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-18 23:49:57] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234951.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-18 23:49:57] å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
ğŸ”„ å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼Œæœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: 4
[2025-10-18 23:49:57] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-18 23:49:57] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-18 23:49:57] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-18 23:49:57] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-18 23:50:13] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 15.54 ç§’
[2025-10-18 23:50:13] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:50:15] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 17.34 ç§’
[2025-10-18 23:50:15] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:50:15] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 17.75 ç§’
[2025-10-18 23:50:15] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:50:15] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 18.23 ç§’
[2025-10-18 23:50:15] è¯†åˆ«å†…å®¹: 
[2025-10-18 23:50:15] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-18 23:50:15] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251018_234951.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """å¤„ç†å•å¼ å›¾ç‰‡ - ä¿®å¤ç‰ˆ"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """å¤„ç†å•å¼ å›¾ç‰‡ - ä¿®å¤ç‰ˆ"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """å¤„ç†å•å¼ å›¾ç‰‡ - ä¿®å¤ç‰ˆ"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:30: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.
  self.ocr = PaddleOCR(
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:02:02] å¼€å§‹åˆå§‹åŒ–PaddleOCR
âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: show_log
[2025-10-19 00:02:02] âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: show_log
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:03:15] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 00:03:22] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 00:03:22] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 00:03:22] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_000315.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ”„ å¼€å§‹ä½¿ç”¨å•çº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
[2025-10-19 00:03:22] å¼€å§‹ä½¿ç”¨å•çº¿ç¨‹å¤„ç†å›¾ç‰‡ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
[2025-10-19 00:03:22] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 00:03:31] âŒ å¤„ç†å›¾ç‰‡ 0032.png å¤±è´¥: 'OCRResult' object has no attribute 'data'

âŒ å¤„ç†å›¾ç‰‡ 0032.png å¤±è´¥: 'OCRResult' object has no attribute 'data'
[2025-10-19 00:03:31] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 00:03:43] âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:03:43] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 00:03:56] âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:03:56] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 00:04:09] âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:04:09] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 00:04:09] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_000315.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 103
    self._log_message(f"è¯†åˆ«å†…å®¹: {recognized_text[:50].replace('\n', ' ')}..." if len(recognized_text) > 50 else f"è¯†åˆ«å†…å®¹: {recognized_text.replace('\n', ' ')}")
                                                                            ^^
SyntaxError: f-string expression part cannot include a backslash
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 203
    print(
         ^
SyntaxError: '(' was never closed
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 203
    print(
         ^
SyntaxError: '(' was never closed
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.
  self.ocr = PaddleOCR(
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:10:24] å¼€å§‹åˆå§‹åŒ–PaddleOCR
âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: use_gpu
[2025-10-19 00:10:24] âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: use_gpu
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[A[A[K[1B[K[1B[K[1B[K[3A[14C[?1l>[?2004l[1B[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hppython    p  iflow     iflowls   iflow     iflow     iflowls   cd ..{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
/home/featurize/work/ocr_cli.py:32: DeprecationWarning: The parameter `rec_batch_num` has been deprecated and will be removed in the future. Please use `text_recognition_batch_size` instead.
  self.ocr = PaddleOCR(
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:51:17] å¼€å§‹åˆå§‹åŒ–PaddleOCR
âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: det_batch_num
[2025-10-19 00:51:17] âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: Unknown argument: det_batch_num
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:51:58] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 00:52:05] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 00:52:05] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 00:52:05] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005158.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 00:52:05] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 00:52:05] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 00:52:14] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 9.55 ç§’
[2025-10-19 00:52:14] è¯†åˆ«å†…å®¹: F  1  å£  â–¡  F  æ–‡å­¦è¿åŠ¨  *  :  äºŒ  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€...
[2025-10-19 00:52:14] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 00:52:27] âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:27] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 00:52:40] âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:40] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 00:52:53] âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:53] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 00:52:53] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005158.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:55:56] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 00:56:02] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 00:56:02] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 00:56:02] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005556.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 00:56:02] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 00:56:02] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 00:56:12] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 9.89 ç§’
[2025-10-19 00:56:12] è¯†åˆ«å†…å®¹: F  1  å£  â–¡  1  æ–‡å­¦è¿åŠ¨  *  :  äºŒ  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€...
[2025-10-19 00:56:12] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 00:56:24] âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:24] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 00:56:37] âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:37] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 00:56:50] âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:50] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 00:56:50] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005556.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:57:05] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 00:57:12] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 00:57:12] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 00:57:12] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005705.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 00:57:12] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 00:57:12] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 00:57:22] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 10.03 ç§’
[2025-10-19 00:57:22] è¯†åˆ«å†…å®¹: F  1  å£  â–¡  1  æ–‡å­¦è¿åŠ¨  *  :  äºŒ  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€...
[2025-10-19 00:57:22] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 00:57:35] âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0033.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:57:35] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 00:57:48] âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0034.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:57:48] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 00:58:01] âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


âŒ å¤„ç†å›¾ç‰‡ 0035.png å¤±è´¥: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:58:01] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 00:58:01] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005705.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mUsing official model (PP-OCRv5_mobile_det), the model files will be automatically downloaded and saved in `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 00:58:16] å¼€å§‹åˆå§‹åŒ–PaddleOCR
Fetching 6 files:   0%|                                                                           | 0/6 [00:00<?, ?it/s]
inference.json: 0.00B [00:00, ?B/s][Ainference.json: 230kB [00:00, 85.6MB/s]

README.md: 0.00B [00:00, ?B/s][A

.gitattributes: 0.00B [00:00, ?B/s][A[A.gitattributes: 1.57kB [00:00, 3.15MB/s]
README.md: 16.2kB [00:00, 7.85MB/s]
Fetching 6 files:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 1/6 [00:00<00:03,  1.41it/s]
inference.yml:   0%|                                                                          | 0.00/903 [00:00<?, ?B/s][Ainference.yml: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 903/903 [00:00<00:00, 2.58MB/s]

config.json: 0.00B [00:00, ?B/s][Aconfig.json: 2.87kB [00:00, 4.80MB/s]

inference.pdiparams:   0%|                                                                  | 0.00/4.69M [00:00<?, ?B/s][A
inference.pdiparams: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.69M/4.69M [00:03<00:00, 1.43MB/s][Ainference.pdiparams: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.69M/4.69M [00:03<00:00, 1.43MB/s]
Fetching 6 files:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 5/6 [00:04<00:00,  1.21it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.46it/s]
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mUsing official model (PP-OCRv5_mobile_rec), the model files will be automatically downloaded and saved in `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
Fetching 6 files:   0%|                                                                           | 0/6 [00:00<?, ?it/s]
.gitattributes: 0.00B [00:00, ?B/s][A.gitattributes: 1.57kB [00:00, 3.30MB/s]
Fetching 6 files:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 1/6 [00:00<00:02,  2.41it/s]
README.md: 0.00B [00:00, ?B/s][AREADME.md: 16.1kB [00:00, 21.3MB/s]

inference.yml: 0.00B [00:00, ?B/s][A

inference.json: 0.00B [00:00, ?B/s][A[Ainference.json: 218kB [00:00, 80.5MB/s]
inference.yml: 148kB [00:00, 2.43MB/s]

config.json: 0.00B [00:00, ?B/s][Aconfig.json: 352kB [00:00, 6.12MB/s]
Fetching 6 files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 3/6 [00:00<00:00,  4.23it/s]
inference.pdiparams:   0%|                                                                  | 0.00/16.5M [00:00<?, ?B/s][A
inference.pdiparams: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.5M/16.5M [00:01<00:00, 11.4MB/s][Ainference.pdiparams: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.5M/16.5M [00:01<00:00, 11.4MB/s]
Fetching 6 files:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 5/6 [00:02<00:00,  2.00it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.65it/s]
[2025-10-19 00:58:27] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 00:58:27] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 00:58:27] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005816.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 00:58:27] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 00:58:27] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 00:58:34] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 7.34 ç§’
[2025-10-19 00:58:34] è¯†åˆ«å†…å®¹: æ–‡å­¦è¿åŠ¨  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€ç§æ–‡ä½“å’Œæ–‡å­¦è¯­è¨€çš„é©  æ–°è¿åŠ¨ã€‚  å¤æ–‡â€æ˜¯å’Œé­...
[2025-10-19 00:58:34] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 00:58:41] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.71 ç§’
[2025-10-19 00:58:41] è¯†åˆ«å†…å®¹: x  å¼ æ–‡ç« åº”æ˜¯ä½œè€…çœŸå®æƒ…æ„Ÿçš„æµéœ²ï¼Œåå¯¹æ— ç—…å‘»åŸï¼Œ  çŸ«æ‰é€   ä½œçš„ä¸è‰¯æ–‡é£ï¼ŒæŒ‡å‡ºï¼š  â€œå¤§å‡¡ç‰©ä¸å¾—...
[2025-10-19 00:58:41] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 00:58:48] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.75 ç§’
[2025-10-19 00:58:48] è¯†åˆ«å†…å®¹: è¿™äº›å¾é›†çš„æ°‘æ­Œä¹Ÿç§°ä½œ  â€œä¹åºœ  æ–°ä¹åºœæ˜¯ç”¨æ–°é¢˜æåˆ›ä½œçš„  0  ä¹æ›²å’Œè¯—ï¼Œå’Œä¹åºœå¤é¢˜ç›¸å¯¹è€Œç§°ã€‚å”ä»£...
[2025-10-19 00:58:48] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 00:58:53] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 5.40 ç§’
[2025-10-19 00:58:53] è¯†åˆ«å†…å®¹: ä¸åŒç¨‹åº¦ä¸Šåæ˜ äº†ç¤¾ä¼šçš„æœ¬è´¨  æ–°ä¹åºœè¿åŠ¨ä½œä¸ºæ–‡å­¦å²ä¸Šçš„ä¸€ç§æ–‡å­¦æ€æ½®ï¼Œå¯¹åä¸–æ–‡å­¦  äº§ç”Ÿäº†å¹¿æ³›çš„å½±å“ï¼Œ...
[2025-10-19 00:58:53] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 00:58:53] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_005816.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 01:00:02] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 01:00:06] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 01:00:06] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 01:00:06] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_010002.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 01:00:06] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 01:00:06] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 01:00:12] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.33 ç§’
[2025-10-19 01:00:12] è¯†åˆ«å†…å®¹: æ–‡å­¦è¿åŠ¨  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€ç§æ–‡ä½“å’Œæ–‡å­¦è¯­è¨€çš„é©  æ–°è¿åŠ¨ã€‚  å¤æ–‡â€æ˜¯å’Œé­...
[2025-10-19 01:00:12] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 01:00:19] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.47 ç§’
[2025-10-19 01:00:19] è¯†åˆ«å†…å®¹: x  å¼ æ–‡ç« åº”æ˜¯ä½œè€…çœŸå®æƒ…æ„Ÿçš„æµéœ²ï¼Œåå¯¹æ— ç—…å‘»åŸï¼Œ  çŸ«æ‰é€   ä½œçš„ä¸è‰¯æ–‡é£ï¼ŒæŒ‡å‡ºï¼š  â€œå¤§å‡¡ç‰©ä¸å¾—...
[2025-10-19 01:00:19] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 01:00:25] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.76 ç§’
[2025-10-19 01:00:25] è¯†åˆ«å†…å®¹: è¿™äº›å¾é›†çš„æ°‘æ­Œä¹Ÿç§°ä½œ  â€œä¹åºœ  æ–°ä¹åºœæ˜¯ç”¨æ–°é¢˜æåˆ›ä½œçš„  0  ä¹æ›²å’Œè¯—ï¼Œå’Œä¹åºœå¤é¢˜ç›¸å¯¹è€Œç§°ã€‚å”ä»£...
[2025-10-19 01:00:25] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 01:00:31] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 5.28 ç§’
[2025-10-19 01:00:31] è¯†åˆ«å†…å®¹: ä¸åŒç¨‹åº¦ä¸Šåæ˜ äº†ç¤¾ä¼šçš„æœ¬è´¨  æ–°ä¹åºœè¿åŠ¨ä½œä¸ºæ–‡å­¦å²ä¸Šçš„ä¸€ç§æ–‡å­¦æ€æ½®ï¼Œå¯¹åä¸–æ–‡å­¦  äº§ç”Ÿäº†å¹¿æ³›çš„å½±å“ï¼Œ...
[2025-10-19 01:00:31] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 01:00:31] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_010002.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32mâœ [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "æ‰§è¡Œå‘½ä»¤: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== å¤ç›˜è®°å½•: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
æ­£åœ¨åˆå§‹åŒ–PaddleOCR...
[2025-10-19 01:03:58] å¼€å§‹åˆå§‹åŒ–PaddleOCR
[2025-10-19 01:04:02] PaddleOCRåˆå§‹åŒ–æˆåŠŸ
âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ
============================================================
ğŸš€ å¼€å§‹æ‰¹é‡OCRè¯†åˆ«
============================================================
[2025-10-19 01:04:02] æ‰¾åˆ° 361 å¼ PNGå›¾ç‰‡
[2025-10-19 01:04:02] ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“ ç­›é€‰å‡º 4 å¼ æµ‹è¯•å›¾ç‰‡: 0032.png, 0033.png, 0034.png, 0035.png
ğŸ“Š æ€»å…±éœ€è¦å¤„ç† 4 å¼ å›¾ç‰‡
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_010358.log
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
[2025-10-19 01:04:02] å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
ğŸ”„ å¼€å§‹æŒ‰é¡ºåºé€å¼ å¤„ç†å›¾ç‰‡
[2025-10-19 01:04:02] å¼€å§‹å¤„ç†å›¾ç‰‡: 0032.png
[2025-10-19 01:04:08] âœ… å›¾ç‰‡ 0032.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.31 ç§’
[2025-10-19 01:04:08] è¯†åˆ«å†…å®¹: æ–‡å­¦è¿åŠ¨  å¤æ–‡è¿åŠ¨  å”ä»£ä¸­æœŸéŸ©æ„ˆã€æŸ³å®—å…ƒæå€¡çš„ä¸€ç§æ–‡ä½“å’Œæ–‡å­¦è¯­è¨€çš„é©  æ–°è¿åŠ¨ã€‚  å¤æ–‡â€æ˜¯å’Œé­...
[2025-10-19 01:04:08] å¼€å§‹å¤„ç†å›¾ç‰‡: 0033.png
[2025-10-19 01:04:15] âœ… å›¾ç‰‡ 0033.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 6.91 ç§’
[2025-10-19 01:04:15] è¯†åˆ«å†…å®¹: x  å¼ æ–‡ç« åº”æ˜¯ä½œè€…çœŸå®æƒ…æ„Ÿçš„æµéœ²ï¼Œåå¯¹æ— ç—…å‘»åŸï¼Œ  çŸ«æ‰é€   ä½œçš„ä¸è‰¯æ–‡é£ï¼ŒæŒ‡å‡ºï¼š  â€œå¤§å‡¡ç‰©ä¸å¾—...
[2025-10-19 01:04:15] å¼€å§‹å¤„ç†å›¾ç‰‡: 0034.png
[2025-10-19 01:04:22] âœ… å›¾ç‰‡ 0034.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 7.13 ç§’
[2025-10-19 01:04:22] è¯†åˆ«å†…å®¹: è¿™äº›å¾é›†çš„æ°‘æ­Œä¹Ÿç§°ä½œ  â€œä¹åºœ  æ–°ä¹åºœæ˜¯ç”¨æ–°é¢˜æåˆ›ä½œçš„  0  ä¹æ›²å’Œè¯—ï¼Œå’Œä¹åºœå¤é¢˜ç›¸å¯¹è€Œç§°ã€‚å”ä»£...
[2025-10-19 01:04:22] å¼€å§‹å¤„ç†å›¾ç‰‡: 0035.png
[2025-10-19 01:04:28] âœ… å›¾ç‰‡ 0035.png å¤„ç†å®Œæˆï¼Œè€—æ—¶ 5.56 ç§’
[2025-10-19 01:04:28] è¯†åˆ«å†…å®¹: ä¸åŒç¨‹åº¦ä¸Šåæ˜ äº†ç¤¾ä¼šçš„æœ¬è´¨  æ–°ä¹åºœè¿åŠ¨ä½œä¸ºæ–‡å­¦å²ä¸Šçš„ä¸€ç§æ–‡å­¦æ€æ½®ï¼Œå¯¹åä¸–æ–‡å­¦  äº§ç”Ÿäº†å¹¿æ³›çš„å½±å“ï¼Œ...
[2025-10-19 01:04:28] å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœåˆ°Markdownæ–‡ä»¶
[2025-10-19 01:04:28] âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
============================================================
ğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼
ğŸ“Š å¤„ç†ç»Ÿè®¡: 4 å¼ å›¾ç‰‡
ğŸ“„ è¾“å‡ºæ–‡ä»¶: /home/featurize/data/ä¸­å›½æ–‡å­¦å²åè¯è§£é‡Š.md
ğŸ“ æ—¥å¿—æ–‡ä»¶: /home/featurize/work/ocr_execution_20251019_010358.log
============================================================
[1m[7m%[27m[1m[0m                                                     