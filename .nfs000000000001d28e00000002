Script started on 2025-10-18 23:31:07+00:00 [TERM="xterm-256color" TTY="/dev/pts/10" COLUMNS="120" LINES="39"]
[1;35m    ______              __                _
   / ____/___   ____ _ / /_ __  __ _____ (_)____  ___
  / /_   / _ \ / __ `// __// / / // ___// //_  / / _ \
 / __/  /  __// /_/ // /_ / /_/ // /   / /  / /_/  __/
/_/     \___/ \__,_/ \__/ \__,_//_/   /_/  /___/\___/
======================================================[0m

„ÄêÁõÆÂΩïÂèä‰ΩúÁî®„Äë

+------------------+---------------------------------+---------+---------------------------------------------------------+
|  ÁõÆÂΩïÂêçÁß∞        | Ë∑ØÂæÑ                            | IO ÊÄßËÉΩ |  ËØ¥Êòé                                                   |
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  ‰∫ëÁ´ØÂêåÊ≠•ÁõÆÂΩï    |  /home/featurize/work           | ÊÖ¢      |  ‰∫ëÂêåÊ≠•Áõò‰∏≠ÁöÑÊï∞ÊçÆ‰ºö‰∏ÄÁõ¥Ë∑üÈöèÁî®Êà∑Ôºå‰∏ç‰ºöÈöèÂÆû‰æãÈÄÄËøòË¢´ÈîÄÊØÅÔºå |
|                  |                                 |         |  ‰ΩÜÂÖ∂ËØªÂèñ/ÂÜôÂÖ•ÊÄßËÉΩÈùûÂ∏∏Â∑Æ„ÄÇ                              |
|                  |                                 |         |  ÊâÄ‰ª•‰∏ÄÂÆö‰∏çË¶ÅÂú®ËøôÈáå‰øùÂ≠òÊï∞ÊçÆÈõÜÔºåÂê¶Âàô‰ºö‰∏•ÈáçÂΩ±ÂìçËÆ≠ÁªÉÊÄßËÉΩ   |
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  Êï∞ÊçÆÈõÜ‰∏ãËΩΩÁõÆÂΩï  |  /home/featurize/data           | Âø´      |  Ê∑ªÂä†Êï∞ÊçÆÈõÜ‰ºö‰∏ãËΩΩÂπ∂Ëß£ÂéãËá≥Ê≠§ÁõÆÂΩïÔºåËØ•ÁõÆÂΩïÁ£ÅÁõò‰∏∫Êú¨Âú∞È´òÈÄü   |
|                  |                                 |         |  Á£ÅÁõòÔºåÂõ†Ê≠§ËØªÂÜôÂæàÂø´„ÄÇÂÆû‰æãÈîÄÊØÅÂêéËá™Âä®Âà†Èô§                 | 
+------------------+---------------------------------+---------+---------------------------------------------------------+
|  ÂÖ∂‰ªñÁõÆÂΩï        |  N / A                          | Âø´      |  ÂÖ∂‰ªñÁõÆÂΩïÂùá‰∏∫Êú¨Âú∞È´òÈÄüÁ£ÅÁõòÔºåÂÆû‰æãÈîÄÊØÅÂêéËá™Âä®Âà†Èô§           |
+------------------+---------------------------------+---------+---------------------------------------------------------+

„ÄêÊúÄ‰Ω≥ÂÆûË∑µ„Äë

[0;32m ‚úÖ  ÂßãÁªà‰ΩøÁî®Êï∞ÊçÆÈõÜÂäüËÉΩÊù•Ê∑ªÂä†Êï∞ÊçÆÔºåÊ∑ªÂä†ÂÆåÊàêÂêéÁõ¥Êé•‰ΩøÁî®Ôºå‰∏çË¶ÅÂÜçÁßªÂä®Êï∞ÊçÆÁöÑ‰ΩçÁΩÆ„ÄÇ
[0;32m ‚úÖ  ÂßãÁªàÂ∞Ü‰ª£Á†Å‰øùÂ≠òËá≥„Äå‰∫ëÁ´ØÂêåÊ≠•ÁõÆÂΩï„Äç‰∏≠„ÄÇ
[0;32m ‚úÖ  ÈáçË¶ÅÁöÑÊ®°ÂûãÊñá‰ª∂‰øùÂ≠òÂú®„Äå‰∫ëÁ´ØÂêåÊ≠•ÁõÆÂΩï„ÄçÔºå‰∏çÈáçË¶ÅÁöÑÊ®°ÂûãÊñá‰ª∂‰øùÂ≠òÂú®ÂÖ∂‰ªñ‰ΩçÁΩÆ„ÄÇ
[0;32m ‚úÖ  ÂßãÁªà‰ΩøÁî® pip ÂÆâË£Ö‰æùËµñÔºåËÄå‰∏çÊòØÁî® condaÔºåÂ¶ÇÊó†ÂøÖË¶ÅÔºå‰∏çË¶ÅÂàõÂª∫ËôöÊãüÁéØÂ¢ÉÔºåÈô§Èùû‰Ω†Áü•ÈÅìËá™Â∑±Âú®ÂÅö‰ªÄ‰πà„ÄÇ
[0;32m ‚úÖ  Â∏∏Áî®ÁöÑÂåÖÂèØ‰ΩøÁî® pip install --user xxx ÂÆâË£ÖÔºåËøôÊ†∑‰∏ãÊ¨°‰ΩøÁî®Êó†ÈúÄÈáçÂ§çÂÆâË£Ö„ÄÇ [0m

„ÄêÊ≥®ÊÑè‰∫ãÈ°π„Äë

[0;31m ‚õîÔ∏è  ‰∫ëÁ´ØÂêåÊ≠•ÁõÆÂΩïÔºàworkÁõÆÂΩïÔºâÊúâÈÖçÈ¢ùÈôêÂà∂ÔºåË∂ÖËøáÈÖçÈ¢ùÂ∞Ü‰∫ßÁîüË¥πÁî®„ÄÇÂÖ∑‰ΩìÁöÑÈ¢ùÂ∫¶ÂèØÁÇπÂáªÂè≥‰∏äËßíÁöÑÂ§¥ÂÉèÁ°ÆËÆ§ÔºåÁî®ÈáèËØ∑‰ΩøÁî® `du -sh ~/work/` Êü•Áúã„ÄÇ
[0;31m ‚õîÔ∏è  ËØ∑‰∏çË¶ÅÂà†Èô§ conda ÁöÑ base ÁéØÂ¢ÉÔºåËøô‰ºöÂØºËá¥Êó†Ê≥ïËÆøÈóÆÂ∑•‰ΩúÂå∫„ÄÇ
[0;31m ‚õîÔ∏è  Featurize Á¶ÅÊ≠¢ÊåñÁüøÔºåËØ∑‰∏çË¶Å‰ΩøÁî® featurize ÁöÑÂÆû‰æãÊåñÁüøÔºå‰∏ÄÁªèÂèëÁé∞Áõ¥Êé•Â∞ÅÂè∑ÊÅï‰∏çÈÄÄÊ¨æ„ÄÇ



[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[7mpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[27m[54D[27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m|[27m [27mt[27me[27me[27m [27m-[27ma[27m [27mo[27mc[27mr[27m_[27ml[27mo[27mg[27m_[27m$[27m([27md[27ma[27mt[27me[27m [27m+[27m%[27mY[27m%[27mm[27m%[27md[27m)[27m.[27ml[27mo[27mg[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-18 23:32:05] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-18 23:32:11] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-18 23:32:11] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-18 23:32:11] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_233205.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-18 23:32:11] ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
üîÑ ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
[2025-10-18 23:32:11] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-18 23:32:11] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-18 23:32:11] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-18 23:32:11] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-18 23:32:28] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 16.47 Áßí
[2025-10-18 23:32:28] ËØÜÂà´ÂÜÖÂÆπ: F
1
Âè£
‚ñ°
F
ÊñáÂ≠¶ËøêÂä®
*
:
‰∫å
Âè§ÊñáËøêÂä®
Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏ÄÁßçÊñá‰ΩìÂíåÊñáÂ≠¶ËØ≠Ë®ÄÁöÑÈù©...
[2025-10-18 23:32:28] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 16.61 Áßí
[2025-10-18 23:32:28] ËØÜÂà´ÂÜÖÂÆπ: ‰∏çÂêåÁ®ãÂ∫¶‰∏äÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑÊú¨Ë¥®„ÄÇ
Êñ∞‰πêÂ∫úËøêÂä®‰Ωú‰∏∫ÊñáÂ≠¶Âè≤‰∏äÁöÑ‰∏ÄÁßçÊñáÂ≠¶ÊÄùÊΩÆÔºåÂØπÂêé‰∏ñÊñáÂ≠¶
‰∫ßÁîü‰∫ÜÂπøÊ≥õÁöÑÂΩ±ÂìçÔºåÂú®...
[2025-10-18 23:32:29] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 17.50 Áßí
[2025-10-18 23:32:29] ËØÜÂà´ÂÜÖÂÆπ: Ëøô‰∫õÂæÅÈõÜÁöÑÊ∞ëÊ≠å‰πüÁß∞‰Ωú
‰πêÂ∫ú‚Äù
4
Êñ∞‰πêÂ∫úÊòØÁî®Êñ∞È¢òÊùêÂàõ‰ΩúÁöÑ
0
‰πêÊõ≤ÂíåËØóÔºåÂíå‰πêÂ∫úÂè§È¢òÁõ∏ÂØπËÄåÁß∞„ÄÇ
'
Âîê...
[2025-10-18 23:32:30] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 19.15 Áßí
[2025-10-18 23:32:30] ËØÜÂà´ÂÜÖÂÆπ: *
Âº†ÊñáÁ´†Â∫îÊòØ‰ΩúËÄÖÁúüÂÆûÊÉÖÊÑüÁöÑÊµÅÈú≤Ôºå
ÂèçÂØπÊó†ÁóÖÂëªÂêüÔºå
Áü´ÊèâÈÄ†
‰ΩúÁöÑ‰∏çËâØÊñáÈ£éÔºå
ÊåáÂá∫Ôºö
Â§ßÂá°Áâ©‰∏çÂæóÂÖ∂Âπ≥Âàô...

‚ùå Á®ãÂ∫èÊâßË°åÂá∫Èîô: '0032.png'
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[?1l>[?2004l
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-18 23:36:35] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-18 23:36:42] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-18 23:36:42] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-18 23:36:42] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_233635.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-18 23:36:42] ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
üîÑ ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
[2025-10-18 23:36:42] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-18 23:36:42] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-18 23:36:42] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-18 23:36:42] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-18 23:36:59] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 16.66 Áßí
[2025-10-18 23:36:59] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 16.67 Áßí
[2025-10-18 23:36:59] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:36:59] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:36:59] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 16.85 Áßí
[2025-10-18 23:36:59] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:36:59] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 17.22 Áßí
[2025-10-18 23:36:59] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:36:59] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-18 23:36:59] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_233635.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hpython ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log[?1l>[?2004l
]2;python ocr_cli.py | tee -a ocr_log_$(date +%Y%m%d).log]1;python[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-18 23:42:40] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-18 23:42:46] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-18 23:42:46] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-18 23:42:46] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234240.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-18 23:42:46] ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
üîÑ ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
[2025-10-18 23:42:46] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-18 23:42:46] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-18 23:42:46] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-18 23:42:46] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-18 23:43:01] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 15.41 Áßí
[2025-10-18 23:43:01] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:43:03] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 17.36 Áßí
[2025-10-18 23:43:03] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:43:04] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 18.01 Áßí
[2025-10-18 23:43:04] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:43:04] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 18.42 Áßí
[2025-10-18 23:43:04] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:43:04] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-18 23:43:04] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234240.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h[7m{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_r[7me[7mview.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> o[7mc[7mr_review.log 2>&1[27m[K
[K[3A[14C[27m{[27m [27me[27mc[27mh[27mo[27m [27m"[27m=[27m=[27m=[27m [27mÂ§ç[27m[27mÁõò[27m[27mËÆ∞[27m[27mÂΩï[27m[27m:[27m [27m$[27m([27md[27ma[27mt[27me[27m [27m'[27m+[27m%[27mY[27m-[27m%[27mm[27m-[27m%[27md[27m [27m%[27mH[27m:[27m%[27mM[27m:[27m%[27mS[27m'[27m)[27m [27m=[27m=[27m=[27m"[27m;[27m [27me[27mc[27mh[27mo[27m [27m"[27mÊâß[27m[27mË°å[27m[27mÂëΩ[27m[27m‰ª§[27m[27m:[27m [27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m$[27m@[27m"[27m;[27m [27m}[27m [27m>[27m>[27m [27mo[27mc[27mr[27m_[27mre[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m2[27m>[27m&[27m1[27m [27m&[27m&[27m [27mp[27my[27mt[27mh[27mo[27mn[27m [27mo[27mc[27mr[27m_[27mc[27ml[27mi[27m.[27mp[27my[27m [27m"[27m$[27m@[27m"[27m [27m|[27m [27mt[27me[27me[27m [27m-[27ma[27m [27mo[27mc[27mr[27m_[27mr[27me[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m&[27m&[27m [27me[27mc[27mh[27mo[27m [27m"[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m-[27m"[27m [27m>[27m>[27m [27moc[27mr[27m_[27mr[27me[27mv[27mi[27me[27mw[27m.[27ml[27mo[27mg[27m [27m2[27m>[27m&[27m1[1B[K[?1l>[?2004l
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-18 23:46:37] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-18 23:46:44] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-18 23:46:44] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-18 23:46:44] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234637.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-18 23:46:44] ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
üîÑ ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
[2025-10-18 23:46:44] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-18 23:46:44] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-18 23:46:44] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-18 23:46:44] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-18 23:47:03] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 19.38 Áßí
[2025-10-18 23:47:03] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:47:04] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 19.72 Áßí
[2025-10-18 23:47:04] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:47:04] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 20.26 Áßí
[2025-10-18 23:47:04] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:47:04] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 20.54 Áßí
[2025-10-18 23:47:04] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:47:04] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-18 23:47:04] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234637.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-18 23:49:51] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-18 23:49:57] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-18 23:49:57] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-18 23:49:57] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234951.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-18 23:49:57] ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
üîÑ ÂºÄÂßã‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºåÊúÄÂ§ßÂπ∂ÂèëÁ∫øÁ®ãÊï∞: 4
[2025-10-18 23:49:57] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-18 23:49:57] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-18 23:49:57] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-18 23:49:57] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-18 23:50:13] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 15.54 Áßí
[2025-10-18 23:50:13] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:50:15] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 17.34 Áßí
[2025-10-18 23:50:15] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:50:15] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 17.75 Áßí
[2025-10-18 23:50:15] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:50:15] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 18.23 Áßí
[2025-10-18 23:50:15] ËØÜÂà´ÂÜÖÂÆπ: 
[2025-10-18 23:50:15] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-18 23:50:15] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251018_234951.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """Â§ÑÁêÜÂçïÂº†ÂõæÁâá - ‰øÆÂ§çÁâà"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """Â§ÑÁêÜÂçïÂº†ÂõæÁâá - ‰øÆÂ§çÁâà"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 74
    """Â§ÑÁêÜÂçïÂº†ÂõæÁâá - ‰øÆÂ§çÁâà"""
    ^
IndentationError: expected an indented block after function definition on line 73
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:30: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.
  self.ocr = PaddleOCR(
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:02:02] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: show_log
[2025-10-19 00:02:02] ‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: show_log
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:03:15] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 00:03:22] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 00:03:22] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 00:03:22] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_000315.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üîÑ ÂºÄÂßã‰ΩøÁî®ÂçïÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºàË∞ÉËØïÊ®°ÂºèÔºâ
[2025-10-19 00:03:22] ÂºÄÂßã‰ΩøÁî®ÂçïÁ∫øÁ®ãÂ§ÑÁêÜÂõæÁâáÔºàË∞ÉËØïÊ®°ÂºèÔºâ
[2025-10-19 00:03:22] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 00:03:31] ‚ùå Â§ÑÁêÜÂõæÁâá 0032.png Â§±Ë¥•: 'OCRResult' object has no attribute 'data'

‚ùå Â§ÑÁêÜÂõæÁâá 0032.png Â§±Ë¥•: 'OCRResult' object has no attribute 'data'
[2025-10-19 00:03:31] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 00:03:43] ‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:03:43] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 00:03:56] ‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:03:56] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 00:04:09] ‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:04:09] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 00:04:09] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_000315.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 103
    self._log_message(f"ËØÜÂà´ÂÜÖÂÆπ: {recognized_text[:50].replace('\n', ' ')}..." if len(recognized_text) > 50 else f"ËØÜÂà´ÂÜÖÂÆπ: {recognized_text.replace('\n', ' ')}")
                                                                            ^^
SyntaxError: f-string expression part cannot include a backslash
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 203
    print(
         ^
SyntaxError: '(' was never closed
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{  File "/home/featurize/work/ocr_cli.py", line 203
    print(
         ^
SyntaxError: '(' was never closed
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.
  self.ocr = PaddleOCR(
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:10:24] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: use_gpu
[2025-10-19 00:10:24] ‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: use_gpu
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[A[A[K[1B[K[1B[K[1B[K[3A[14C[?1l>[?2004l[1B[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004hppython    p  iflow     iflowls   iflow     iflow     iflowls   cd ..{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
/home/featurize/work/ocr_cli.py:32: DeprecationWarning: The parameter `rec_batch_num` has been deprecated and will be removed in the future. Please use `text_recognition_batch_size` instead.
  self.ocr = PaddleOCR(
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:51:17] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: det_batch_num
[2025-10-19 00:51:17] ‚ùå PaddleOCRÂàùÂßãÂåñÂ§±Ë¥•: Unknown argument: det_batch_num
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:51:58] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 00:52:05] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 00:52:05] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 00:52:05] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005158.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 00:52:05] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 00:52:05] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 00:52:14] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 9.55 Áßí
[2025-10-19 00:52:14] ËØÜÂà´ÂÜÖÂÆπ: F  1  Âè£  ‚ñ°  F  ÊñáÂ≠¶ËøêÂä®  *  :  ‰∫å  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏Ä...
[2025-10-19 00:52:14] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 00:52:27] ‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:27] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 00:52:40] ‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:40] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 00:52:53] ‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.225708GB memory has been allocated and available memory is only 1.434448GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:52:53] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 00:52:53] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005158.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:55:56] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 00:56:02] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 00:56:02] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 00:56:02] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005556.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 00:56:02] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 00:56:02] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 00:56:12] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 9.89 Áßí
[2025-10-19 00:56:12] ËØÜÂà´ÂÜÖÂÆπ: F  1  Âè£  ‚ñ°  1  ÊñáÂ≠¶ËøêÂä®  *  :  ‰∫å  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏Ä...
[2025-10-19 00:56:12] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 00:56:24] ‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:24] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 00:56:37] ‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:37] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 00:56:50] ‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:56:50] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 00:56:50] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005556.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_server_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_det`.[0m
[32mCreating model: ('PP-OCRv5_server_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_server_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:57:05] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 00:57:12] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 00:57:12] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 00:57:12] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005705.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 00:57:12] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 00:57:12] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 00:57:22] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 10.03 Áßí
[2025-10-19 00:57:22] ËØÜÂà´ÂÜÖÂÆπ: F  1  Âè£  ‚ñ°  1  ÊñáÂ≠¶ËøêÂä®  *  :  ‰∫å  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏Ä...
[2025-10-19 00:57:22] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 00:57:35] ‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0033.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
9   void phi::fusion::FusedConv2dAddActKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, std::string const&, std::vector<int, std::allocator<int> > const&, bool, int, float, phi::DenseTensor*, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
10  phi::DnnWorkspaceHandle::ReallocWorkspace(unsigned long)
11  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.216699GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:57:35] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 00:57:48] ‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0034.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:57:48] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 00:58:01] ‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)


‚ùå Â§ÑÁêÜÂõæÁâá 0035.png Â§±Ë¥•: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::AnalysisPredictor::ZeroCopyRun(bool)
1   paddle::framework::NaiveExecutor::RunInterpreterCore(std::vector<std::string, std::allocator<std::string > > const&, bool, bool)
2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
3   paddle::framework::PirInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)
4   paddle::framework::PirInterpreter::TraceRunImpl()
5   paddle::framework::PirInterpreter::TraceRunInstructionList(std::vector<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> >, std::allocator<std::unique_ptr<paddle::framework::InstructionBase, std::default_delete<paddle::framework::InstructionBase> > > > const&)
6   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
7   paddle::framework::PhiKernelInstruction::Run()
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*), &(void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 1, 0, 0, phi::GPUContext const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&)
9   void phi::NearestInterpKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > > const&, paddle::optional<phi::DenseTensor> const&, std::string const&, int, int, int, std::vector<float, std::allocator<float> > const&, std::string const&, bool, int, phi::DenseTensor*)
10  float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
11  phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::Allocator::Allocate(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 3.027344GB memory on GPU 0, 10.217896GB memory has been allocated and available memory is only 1.442261GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[2025-10-19 00:58:01] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 00:58:01] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005705.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mUsing official model (PP-OCRv5_mobile_det), the model files will be automatically downloaded and saved in `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 00:58:16] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
Fetching 6 files:   0%|                                                                           | 0/6 [00:00<?, ?it/s]
inference.json: 0.00B [00:00, ?B/s][Ainference.json: 230kB [00:00, 85.6MB/s]

README.md: 0.00B [00:00, ?B/s][A

.gitattributes: 0.00B [00:00, ?B/s][A[A.gitattributes: 1.57kB [00:00, 3.15MB/s]
README.md: 16.2kB [00:00, 7.85MB/s]
Fetching 6 files:  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1/6 [00:00<00:03,  1.41it/s]
inference.yml:   0%|                                                                          | 0.00/903 [00:00<?, ?B/s][Ainference.yml: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 903/903 [00:00<00:00, 2.58MB/s]

config.json: 0.00B [00:00, ?B/s][Aconfig.json: 2.87kB [00:00, 4.80MB/s]

inference.pdiparams:   0%|                                                                  | 0.00/4.69M [00:00<?, ?B/s][A
inference.pdiparams: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.69M/4.69M [00:03<00:00, 1.43MB/s][Ainference.pdiparams: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.69M/4.69M [00:03<00:00, 1.43MB/s]
Fetching 6 files:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 5/6 [00:04<00:00,  1.21it/s]Fetching 6 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.46it/s]
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mUsing official model (PP-OCRv5_mobile_rec), the model files will be automatically downloaded and saved in `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
Fetching 6 files:   0%|                                                                           | 0/6 [00:00<?, ?it/s]
.gitattributes: 0.00B [00:00, ?B/s][A.gitattributes: 1.57kB [00:00, 3.30MB/s]
Fetching 6 files:  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1/6 [00:00<00:02,  2.41it/s]
README.md: 0.00B [00:00, ?B/s][AREADME.md: 16.1kB [00:00, 21.3MB/s]

inference.yml: 0.00B [00:00, ?B/s][A

inference.json: 0.00B [00:00, ?B/s][A[Ainference.json: 218kB [00:00, 80.5MB/s]
inference.yml: 148kB [00:00, 2.43MB/s]

config.json: 0.00B [00:00, ?B/s][Aconfig.json: 352kB [00:00, 6.12MB/s]
Fetching 6 files:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 3/6 [00:00<00:00,  4.23it/s]
inference.pdiparams:   0%|                                                                  | 0.00/16.5M [00:00<?, ?B/s][A
inference.pdiparams: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.5M/16.5M [00:01<00:00, 11.4MB/s][Ainference.pdiparams: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.5M/16.5M [00:01<00:00, 11.4MB/s]
Fetching 6 files:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 5/6 [00:02<00:00,  2.00it/s]Fetching 6 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.65it/s]
[2025-10-19 00:58:27] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 00:58:27] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 00:58:27] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005816.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 00:58:27] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 00:58:27] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 00:58:34] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 7.34 Áßí
[2025-10-19 00:58:34] ËØÜÂà´ÂÜÖÂÆπ: ÊñáÂ≠¶ËøêÂä®  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏ÄÁßçÊñá‰ΩìÂíåÊñáÂ≠¶ËØ≠Ë®ÄÁöÑÈù©  Êñ∞ËøêÂä®„ÄÇ  Âè§Êñá‚ÄùÊòØÂíåÈ≠è...
[2025-10-19 00:58:34] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 00:58:41] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.71 Áßí
[2025-10-19 00:58:41] ËØÜÂà´ÂÜÖÂÆπ: x  Âº†ÊñáÁ´†Â∫îÊòØ‰ΩúËÄÖÁúüÂÆûÊÉÖÊÑüÁöÑÊµÅÈú≤ÔºåÂèçÂØπÊó†ÁóÖÂëªÂêüÔºå  Áü´ÊèâÈÄ†  ‰ΩúÁöÑ‰∏çËâØÊñáÈ£éÔºåÊåáÂá∫Ôºö  ‚ÄúÂ§ßÂá°Áâ©‰∏çÂæó...
[2025-10-19 00:58:41] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 00:58:48] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.75 Áßí
[2025-10-19 00:58:48] ËØÜÂà´ÂÜÖÂÆπ: Ëøô‰∫õÂæÅÈõÜÁöÑÊ∞ëÊ≠å‰πüÁß∞‰Ωú  ‚Äú‰πêÂ∫ú  Êñ∞‰πêÂ∫úÊòØÁî®Êñ∞È¢òÊùêÂàõ‰ΩúÁöÑ  0  ‰πêÊõ≤ÂíåËØóÔºåÂíå‰πêÂ∫úÂè§È¢òÁõ∏ÂØπËÄåÁß∞„ÄÇÂîê‰ª£...
[2025-10-19 00:58:48] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 00:58:53] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 5.40 Áßí
[2025-10-19 00:58:53] ËØÜÂà´ÂÜÖÂÆπ: ‰∏çÂêåÁ®ãÂ∫¶‰∏äÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑÊú¨Ë¥®  Êñ∞‰πêÂ∫úËøêÂä®‰Ωú‰∏∫ÊñáÂ≠¶Âè≤‰∏äÁöÑ‰∏ÄÁßçÊñáÂ≠¶ÊÄùÊΩÆÔºåÂØπÂêé‰∏ñÊñáÂ≠¶  ‰∫ßÁîü‰∫ÜÂπøÊ≥õÁöÑÂΩ±ÂìçÔºå...
[2025-10-19 00:58:53] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 00:58:53] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_005816.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 01:00:02] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 01:00:06] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 01:00:06] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 01:00:06] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_010002.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 01:00:06] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 01:00:06] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 01:00:12] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.33 Áßí
[2025-10-19 01:00:12] ËØÜÂà´ÂÜÖÂÆπ: ÊñáÂ≠¶ËøêÂä®  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏ÄÁßçÊñá‰ΩìÂíåÊñáÂ≠¶ËØ≠Ë®ÄÁöÑÈù©  Êñ∞ËøêÂä®„ÄÇ  Âè§Êñá‚ÄùÊòØÂíåÈ≠è...
[2025-10-19 01:00:12] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 01:00:19] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.47 Áßí
[2025-10-19 01:00:19] ËØÜÂà´ÂÜÖÂÆπ: x  Âº†ÊñáÁ´†Â∫îÊòØ‰ΩúËÄÖÁúüÂÆûÊÉÖÊÑüÁöÑÊµÅÈú≤ÔºåÂèçÂØπÊó†ÁóÖÂëªÂêüÔºå  Áü´ÊèâÈÄ†  ‰ΩúÁöÑ‰∏çËâØÊñáÈ£éÔºåÊåáÂá∫Ôºö  ‚ÄúÂ§ßÂá°Áâ©‰∏çÂæó...
[2025-10-19 01:00:19] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 01:00:25] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.76 Áßí
[2025-10-19 01:00:25] ËØÜÂà´ÂÜÖÂÆπ: Ëøô‰∫õÂæÅÈõÜÁöÑÊ∞ëÊ≠å‰πüÁß∞‰Ωú  ‚Äú‰πêÂ∫ú  Êñ∞‰πêÂ∫úÊòØÁî®Êñ∞È¢òÊùêÂàõ‰ΩúÁöÑ  0  ‰πêÊõ≤ÂíåËØóÔºåÂíå‰πêÂ∫úÂè§È¢òÁõ∏ÂØπËÄåÁß∞„ÄÇÂîê‰ª£...
[2025-10-19 01:00:25] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 01:00:31] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 5.28 Áßí
[2025-10-19 01:00:31] ËØÜÂà´ÂÜÖÂÆπ: ‰∏çÂêåÁ®ãÂ∫¶‰∏äÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑÊú¨Ë¥®  Êñ∞‰πêÂ∫úËøêÂä®‰Ωú‰∏∫ÊñáÂ≠¶Âè≤‰∏äÁöÑ‰∏ÄÁßçÊñáÂ≠¶ÊÄùÊΩÆÔºåÂØπÂêé‰∏ñÊñáÂ≠¶  ‰∫ßÁîü‰∫ÜÂπøÊ≥õÁöÑÂΩ±ÂìçÔºå...
[2025-10-19 01:00:31] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 01:00:31] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_010002.log
============================================================
[1m[7m%[27m[1m[0m                                                                                                                        ]2;featurize@featurize:~/work]1;~/work]7;file://featurize/home/featurize/work\[0m[27m[24m[J(base) [01;32m‚ûú [01;32m[36mwork[01;34m[01;34m[00m [K[?1h=[?2004h{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo "ÊâßË°åÂëΩ‰ª§: python ocr_cli.py $@"; } >> ocr_review.log 2>&1 && python ocr_cli.py "$@" | tee -a ocr_review.log && echo "----------------------------------------" >> ocr_review.log 2>&1[K
[K[A[18C[1B[K[A[18C[?1l>[?2004l[1B
]2;{ echo "=== Â§çÁõòËÆ∞ÂΩï: $(date '+%Y-%m-%d %H:%M:%S') ==="; echo ; } >> ]1;{/home/featurize/work/ocr_cli.py:32: UserWarning: `lang` and `ocr_version` will be ignored when model names or model directories are not `None`.
  self.ocr = PaddleOCR(
[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.[0m
/environment/miniconda3/lib/python3.11/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
[32mCreating model: ('UVDoc', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/UVDoc`.[0m
[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.[0m
[32mCreating model: ('PP-OCRv5_mobile_det', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_det`.[0m
[32mCreating model: ('PP-OCRv5_mobile_rec', None)[0m
[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/featurize/.paddlex/official_models/PP-OCRv5_mobile_rec`.[0m
Ê≠£Âú®ÂàùÂßãÂåñPaddleOCR...
[2025-10-19 01:03:58] ÂºÄÂßãÂàùÂßãÂåñPaddleOCR
[2025-10-19 01:04:02] PaddleOCRÂàùÂßãÂåñÊàêÂäü
‚úÖ PaddleOCRÂàùÂßãÂåñÊàêÂäü
============================================================
üöÄ ÂºÄÂßãÊâπÈáèOCRËØÜÂà´
============================================================
[2025-10-19 01:04:02] ÊâæÂà∞ 361 Âº†PNGÂõæÁâá
[2025-10-19 01:04:02] Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìù Á≠õÈÄâÂá∫ 4 Âº†ÊµãËØïÂõæÁâá: 0032.png, 0033.png, 0034.png, 0035.png
üìä ÊÄªÂÖ±ÈúÄË¶ÅÂ§ÑÁêÜ 4 Âº†ÂõæÁâá
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_010358.log
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
[2025-10-19 01:04:02] ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
üîÑ ÂºÄÂßãÊåâÈ°∫Â∫èÈÄêÂº†Â§ÑÁêÜÂõæÁâá
[2025-10-19 01:04:02] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0032.png
[2025-10-19 01:04:08] ‚úÖ ÂõæÁâá 0032.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.31 Áßí
[2025-10-19 01:04:08] ËØÜÂà´ÂÜÖÂÆπ: ÊñáÂ≠¶ËøêÂä®  Âè§ÊñáËøêÂä®  Âîê‰ª£‰∏≠ÊúüÈü©ÊÑà„ÄÅÊü≥ÂÆóÂÖÉÊèêÂÄ°ÁöÑ‰∏ÄÁßçÊñá‰ΩìÂíåÊñáÂ≠¶ËØ≠Ë®ÄÁöÑÈù©  Êñ∞ËøêÂä®„ÄÇ  Âè§Êñá‚ÄùÊòØÂíåÈ≠è...
[2025-10-19 01:04:08] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0033.png
[2025-10-19 01:04:15] ‚úÖ ÂõæÁâá 0033.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 6.91 Áßí
[2025-10-19 01:04:15] ËØÜÂà´ÂÜÖÂÆπ: x  Âº†ÊñáÁ´†Â∫îÊòØ‰ΩúËÄÖÁúüÂÆûÊÉÖÊÑüÁöÑÊµÅÈú≤ÔºåÂèçÂØπÊó†ÁóÖÂëªÂêüÔºå  Áü´ÊèâÈÄ†  ‰ΩúÁöÑ‰∏çËâØÊñáÈ£éÔºåÊåáÂá∫Ôºö  ‚ÄúÂ§ßÂá°Áâ©‰∏çÂæó...
[2025-10-19 01:04:15] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0034.png
[2025-10-19 01:04:22] ‚úÖ ÂõæÁâá 0034.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 7.13 Áßí
[2025-10-19 01:04:22] ËØÜÂà´ÂÜÖÂÆπ: Ëøô‰∫õÂæÅÈõÜÁöÑÊ∞ëÊ≠å‰πüÁß∞‰Ωú  ‚Äú‰πêÂ∫ú  Êñ∞‰πêÂ∫úÊòØÁî®Êñ∞È¢òÊùêÂàõ‰ΩúÁöÑ  0  ‰πêÊõ≤ÂíåËØóÔºåÂíå‰πêÂ∫úÂè§È¢òÁõ∏ÂØπËÄåÁß∞„ÄÇÂîê‰ª£...
[2025-10-19 01:04:22] ÂºÄÂßãÂ§ÑÁêÜÂõæÁâá: 0035.png
[2025-10-19 01:04:28] ‚úÖ ÂõæÁâá 0035.png Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂ 5.56 Áßí
[2025-10-19 01:04:28] ËØÜÂà´ÂÜÖÂÆπ: ‰∏çÂêåÁ®ãÂ∫¶‰∏äÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑÊú¨Ë¥®  Êñ∞‰πêÂ∫úËøêÂä®‰Ωú‰∏∫ÊñáÂ≠¶Âè≤‰∏äÁöÑ‰∏ÄÁßçÊñáÂ≠¶ÊÄùÊΩÆÔºåÂØπÂêé‰∏ñÊñáÂ≠¶  ‰∫ßÁîü‰∫ÜÂπøÊ≥õÁöÑÂΩ±ÂìçÔºå...
[2025-10-19 01:04:28] ÂºÄÂßã‰øùÂ≠òËØÜÂà´ÁªìÊûúÂà∞MarkdownÊñá‰ª∂
[2025-10-19 01:04:28] ‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
‚úÖ ËØÜÂà´ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
============================================================
üéâ ÊâÄÊúâÂõæÁâáÂ§ÑÁêÜÂÆåÊàêÔºÅ
üìä Â§ÑÁêÜÁªüËÆ°: 4 Âº†ÂõæÁâá
üìÑ ËæìÂá∫Êñá‰ª∂: /home/featurize/data/‰∏≠ÂõΩÊñáÂ≠¶Âè≤ÂêçËØçËß£Èáä.md
üìù Êó•ÂøóÊñá‰ª∂: /home/featurize/work/ocr_execution_20251019_010358.log
============================================================
[1m[7m%[27m[1m[0m                                                     